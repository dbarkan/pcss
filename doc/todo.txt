test runners have one error for each feature type
all tests subclass test
decide whether to propogate feature errors for all peptides in protein
check memory profile
validate runInfo, pcssFileAttributes
close filehandles
try other disopred dbs for time, fix test_sequence_long
all plow stuff
have DefinedPeptideImporter get max peptide length from input
     frontend was doing this before, backend a better place? scan user has to set though, but might be OK if not symmetrical...think about it

places that change across trombone / mac
testPcssConig:
home_pcss_directory
dssp_command

internalConfig:
home-pcss_dir
svm learn
svm classify

timing:
nr: time 20 min but didn't print exact outpu ttime, saw it later  seqs       21496717
uniprot90 time   seqs 9151522



TEST
have all tests subclass pcss test, which looks for the config file itself. 
change test config so that there is one root directory and that is the only thing that needs to be changed
have test check for operating system and run svm type accordingly
disable or hack tests that retrieve from modbase or run disopred/psipred
have test for exception in pcssSvm.finalizeFeature()

CONTEXT -- Normal Annotation no input, write output (AnnotationRunner)
CONTEXT -- Annotation and SVM Application no input, write output (SvmApplicationRunner) -- features are both input and output and svm is output only
CONTEXT -- SVM Application from file, read input, write output -- same attribute file as above
CONTEXT -- Training Annotation -- no input, all features output along with positive / negaitve (defined by user)
CONTEXT -- Training benchmarking -- input from file, output is the same as input. 
CONTEXT -- Training benchmarking, peptides in memory -- no inpu, output is the same as above
make runner for it

TRAINING ERRORS
If I have an error for a feature for one peptide, it applies for all peptides in the protein. best way to handle?
have error test to make sure all peptides have feature error when the first one gets it
consider whether to hardcode jackknife fraction


MULTIPLE RUNS
print out number of negatives in the test set so we can make sure it is the same across each training iterations
when have multiple psts, validate all have the same length
have test for training runner, exact file match, after done with the 'processAllResults' equivalent
in annotation mode, try to throw a global exception while annotation file is open to make sure it closes file correctly
do context with peptides read in memory and then immediately to training / test -- do some profiling to see how long it takes
training overall:
1. make annotation, write to output file (has positive / negative tag)
2. read back in -- this will be the cluster way, although command line could go directly from memory
3. not writing back out since they don't have to be scored -- although could. 
4. big decision will be whether to write status -- think I should. can have true postivie / negative and also predicte positive / negative -- so status will always be output for a peptide
run an svm classification file through web server in run through svm application mode, same model file, same benchmark file,  
    and see if we get same or similar scores before and after (not really multiple runs issue but do it at the same time)


ANNOTATION
consider having one feature error of each type in annotation output and anything that reads in an annotation file for all normal / runner processing 
	 just need dssp, disopred, psipred -- working on disopred now
         disopred error -- changed file ffef0e2dd621d6a5fc2851aef4341226MESAYTRS|Q16572 -- in disopred file changed position 484 from V (wildtype) to R (induced error)
	 peptides different length -- sequence ffac1dc8985f57c80dd0b64a519b9adbMPNFVENT peptide at position 23 (FPRDPAR) has 7 residues instead of 8. this is only in test input
	 svmTrainingAnnotationInput
have test with annotaiton defined, one peptide that is different lengths than others
handle no peptides parsed for any sequences



TRAINING
will have context for single and multiple iterations
single assumes that someone else will come along and read all directories with result files
multiple will do it itself
however, won't output to its own directory-- just make a class, point it to a fiel, and say add result or something
then single can reuse the directory each time, multiple can have files from different directories

SVM
handle peptides less than canonical length
       make sure to consider getEmptyFeatureOffset too


LARGER DATA:
make sure bestModel still works when have multiple models (currently sorted works, but only two models)
a couple spot checks on svm model
would be great to see if current svm model is the same as a previous model in the perl code
See what is using 1GB when run on 80 seqs -- see if I can find profiler
all contexts: no peptides parsed for all input sequences. don't think it is an issue but just in case

REFACTORING
consider moving svm classify command and svm learn command from internal to pcssConfig to avoid having to keep pcss_directory in that file
all internal config files should have explicit method from runner for retrieval rather than having whatever needs it being able to access the runner's internal config
    esp since they are usually in a special directory
have destination directory for models have two letter directory unless I decide to just copy each time
take out instance data for pcesProtein, pcssPeptide - have it all be getModbaseSequenceId() and then goes to the attribute dictionary
change disorder variable names to disopred
move all data into their own subdirectory
have specialized fasta readers to parse fasta header
can have these specialised fasta readers check to make sure all proteins have sequences instead of way I'm currently doing it
getTwoLetterDir and getThreeLetterDir return differnt directory structures; synergize them
have modelattribute types all be string atttribute objects, then have PCssIo not have to do checks for model string attributes as "" in setValueFromFile
keyword for no errors instead of hardcoding "none", same for no peptide parsed
isError in pcssIo shouldn't be hardcoded
right now we tell a feature it has an error by setting it to be a string attribute with an error prefix value. Better way would be to have a flag for that feature that says if it's an error. Can have the flag be on the superclass. when reading from attribute file, would have to then initialize the feature as its own class with the flag set rather than as a string attribute which is what is happening now.
change references to model to be homology model and svm model to be svm model to distinguish them
have every pcss global exception have an error code that the test can check to make sure the right error is being thrown -- will have a lot, consider if worth it
     or have them all be pcss global exception subclasses

LOGGING
be very explicit about config file errors; make sure that the actual config file that failed is named (internal vs user)

ERRORS / TESTING
validate runinfo
validate pcssFileAttributes
take out exception in getModelStyle,
have tests for problems in rules file - same as in frontend
fix test_sequence_long -- produces different result for the long sequence than previous (need to see if this is the same result on cluster)
make sure files are always closed
     also make sure these are closed when handling exception

CODE
attribute file names / locations shold be internal keywords (maybe)
consider having sorted peptide list in ClassifySvm be finalized or constant so it can't be resorted, or some other way to keep those peptides
	 sorted in that order
explicit vs implicit zeroes for sequence feature
figure out something for relative directories and home test directory in config
soon will have to come up with parameters for different contexts. e.g. application SVM should have model file  / benchmark scores as config (and there need to decide internal vs user); training should have them as output (probably internal). Same thing for annotation output file
move annotationOutput file to internal cofnig
methods for old style run  info
total model count
template pdb
other features (model url)
change acc call to letters
change secondary structure styel to be like amino acids: three features per call, set the feature that is my call to 1

SEQUENCE FEATURES:
explore using different blast database besides nr (maybe nr95?)
psipred and disopred standalone script (probably cluster) and SOP


PLOW
git commit
logging / stats
log all exception messages as error
go through peptide pipeline to see if i missed anything

PRODUCTION
consider whether to have parameters specific to certain contexts or to have one for all contexts
	 one factor is that it will be harder to validate that everything was set in the config file if I have one global file. keep it global for now.
if running with SVM Annotation Input mode, need to link the fasta file for sequences with the original fasta file that was passed. 
   functionality will be different depending on whether fasta file was scan or defined -- could be time to make specialized fasta readers
   don't think I had to do this before since I was alwyas essentailly svm annotaiton features mode

WEB SERVER:
run through svm application mode and see if we get same or similar scores before and after
be sure to test what happens if there are so many peptide mismatches that there are more negatives than positives. is this checked before or after
retrieving sequences?
also consider outputting these to annotation file. this will necessitate checking to make sure they aren't processed at each step

maybe process sequences in increasing size. That way a long sequence won't time out and kill it for the rest of the sequences
If one long sequence does kill it for the rest of the sequences (regardless of whether they were sorted in increasing size),
see what the output looks like -- are there just feature errors for everything that didn't get processed but only one error 
actually saying what happened for the one sequence? Could have an attribute for pcssProteins that says if the algorithm started 
to run, that way we would know if it ran and had an error vs never ran because something else timed out. 

In pcssFeatureHandler, make sure timeout feature exception message will work (the problem is that on the cluster, might be
raising exceptions but they don't get caught because the whole code that is also processing exceptions dies during the timeout)

see if I did anything with the peptides that said keyword sequence mismatch other than write to log file

decide whether to always copy models every run or copy to a pcss directory and cache there. Decision should be based on speed. 
Disopred caches but there is no sali lab disopred results AFAIK, while there is a salilab modbase result. for now will just copy to run directory

will have to test different context flows to make sure if one has an error the other one skips it and proceeds as normal -- all combinations of contexts

can't remember if I am requireing the user to have a keyword for application defined mode. if not, don't, and do it myself when I create the fasta file
definedPeptideImporter should check the keyword (application)

right now annotationFileAttributs has status with input only. Sort of a hack, but needed so that defined mode can set peptide status attribute.
think of a better way to do this after writing more contexts.

Exception guidelines
if I am expecting a source file that I am copying or moving to exist, check to make sure it does and throw feature/protein exception if not; then run shutil (don't rely on that for exception)

for each exception:
make sure it is the right kind of exception
make sure there is a test for it or if not notate it needs one
make sure that features get peptides and proteins and fullproteins get protein somewhere along the way
